{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cc08931",
   "metadata": {},
   "source": [
    "#### **Bleu** (Bilingual evaluation understudy) can be defined as the algorithm for evaluating the quality of the text that has been Machine-Translated (MT) from one language to the other (Papineni et al. 2002). \n",
    "\n",
    "Bleu score ranges between 0 and 1, with values closer to 1 indicating more similar texts from the translation. Invented at IBM in 2001, it was one of the first metric to attain a high correlation with human translations, and still remains the most automated and inexpensive metric to gauge translation quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2638a94",
   "metadata": {},
   "source": [
    "# Bleu Formula\n",
    "$$\n",
    "\\textrm{BLEU} = BP \\times \\exp {1\\over N} \\sum_{n=1}^N \\log p_n\n",
    "$$\n",
    "\n",
    "Where: \n",
    "$$\n",
    "p_n = {\\textrm{Number of ngram tokens in system and reference translations} \\over \\textrm{Number of ngram tokens in system translation}}\n",
    "$$\n",
    "\n",
    "And:\n",
    "\n",
    "The brevity penalty = $\\exp(1-r/c)$, where $c$ is the length of the hypothesis translation (in tokens), and $r$ is the length of the *closest* reference translation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc8c5ef",
   "metadata": {},
   "source": [
    "##### We need to implement Bleu in Python for possible automations in other studies. Hence we start with the hypothesis and reference sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12eeb314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries needed\n",
    "from math import sqrt, log, exp\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "701ada7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis=\"Abandon all hope , ye who enter here\"\n",
    "references=[\"All hope abandon , ye who enter here\", \"All hope abandon , ye who enter in !\", \"Leave every hope, ye that enter\", \"Leave all hope , ye that enter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f805576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the n-grams from the given text\n",
    "def get_ngrams(text, order):\n",
    "    \"\"\"\n",
    "    Given a string `text` and an integer `order`, returns a Counter object containing\n",
    "    the frequency counts of all ngrams of size `order` in the string.\n",
    "    \"\"\"\n",
    "    ngrams = Counter()\n",
    "\n",
    "    words = text.split()\n",
    "    for i in range(len(words)- order+1):\n",
    "      ngram = \" \". join(words[i: i + order])\n",
    "      ngrams[ngram] += 1\n",
    "\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68a9d0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Abandon all': 1, 'all hope': 1, 'hope ,': 1, ', ye': 1, 'ye who': 1, 'who enter': 1, 'enter here': 1}\n"
     ]
    }
   ],
   "source": [
    "print(dict(get_ngrams(hypothesis, 2))) # sanity check: expected output should be\n",
    "# {'Abandon all': 1, 'all hope': 1, 'hope ,': 1, ', ye': 1, 'ye who': 1, 'who enter': 1, 'enter here': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f0d3c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(hypothesis, references):\n",
    "    \n",
    "    bleu=0\n",
    "    p1=0\n",
    "    p2=0\n",
    "    p3=0\n",
    "    p4=0\n",
    "    bp=1\n",
    "    \n",
    "    # BEGIN SOLUTION\n",
    "\n",
    "    # 1. Find the closest reference to the hypothesis\n",
    "    closest_size=100000\n",
    "    closest_ref=[]\n",
    "\n",
    "    for ref in references:\n",
    "      ref_size = len(ref)\n",
    "      if abs(len(hypothesis) - ref_size) < closest_size:\n",
    "        closest_size = abs(len(hypothesis) - ref_size)\n",
    "        closest_ref = ref\n",
    "        pass\n",
    "\n",
    "    # 2. Calculating pn\n",
    "    pns=[]\n",
    "    for order in range(1,5):\n",
    "      # calculate intersection and union of n-grams\n",
    "      # hint: use the get_ngrams function you implemented\n",
    "      # calculate pn for each order\n",
    "        hyp_ngrams = get_ngrams(hypothesis, order)\n",
    "        hyp_count = Counter(hyp_ngrams)\n",
    "        closest_ref_ngrams = get_ngrams(closest_ref, order)\n",
    "        closest_ref_count = Counter(closest_ref_ngrams)\n",
    "        intersection_count = dict(hyp_count & closest_ref_count)\n",
    "        intersection_size = sum(intersection_count.values())\n",
    "        hyp_size = max(len(hyp_ngrams), 1)\n",
    "        p_n = intersection_size / hyp_size\n",
    "        pns.append(p_n)\n",
    "        pass\n",
    "\n",
    "    # 3. Calculating the brevity penalty\n",
    "    bp=1\n",
    "    c=len(hypothesis)\n",
    "    r=min(abs(len(ref) - c) for ref in references)\n",
    "    if c > r:\n",
    "      bp = 1.0\n",
    "    else:\n",
    "      bp = exp(1 - r / c)\n",
    "\n",
    "    # 4. Calculating the BLEU score\n",
    "    weights = [0.25] * 4\n",
    "    bleu=bp * exp(sum(w * log(p_n) for w, p_n in zip(weights, pns)))    \n",
    "    \n",
    "    # Assigning values to p1, p2, p3, p4!\n",
    "    p1, p2, p3, p4 = pns\n",
    "\n",
    "    \n",
    "    # Do not change the variable name\n",
    "    return bleu, p1, p2, p3, p4, bp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80ccca41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.541\n"
     ]
    }
   ],
   "source": [
    "bleu, p1, p2, p3, p4, bp=calculate_bleu(hypothesis, references)\n",
    "print(\"BLEU: %.3f\" % bleu) # sanity check: 0.5 < BLEU < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9b06b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
