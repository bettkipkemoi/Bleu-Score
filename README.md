Bleu (Bilingual evaluation understudy) can be defined as the algorithm for evaluating the quality of the text that has been Machine-Translated (MT) from one language to the other (Papineni et al. 2002).
Bleu score ranges between 0 and 1, with values closer to 1 indicating more similar texts from the translation. Invented at IBM in 2001, it was one of the first metric to attain a high correlation with human translations, and still remains the most automated and inexpensive metric to gauge translation quality.
